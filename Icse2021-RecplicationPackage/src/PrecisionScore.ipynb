{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598515974137",
   "display_name": "Python 3.6.8 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Constants as Const\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import DataLoader\n",
    "\n",
    "ISSUE_ID = 'user_feedback_id'\n",
    "MATCHING = 'Matching Bug Report'\n",
    "SIMILARITY = 'Similarity'\n",
    "FOUND_BUG = 'found_relevant_issue_manually'\n",
    "\n",
    "\n",
    "df = DataLoader.load_resolved_sheet()\n",
    "df = df[~df[FOUND_BUG]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Overall Mean Average Precision@3:   0.55\n\nOverall Mean Average Precision@2:   0.53\n\nOverall Mean Average Precision@1:   0.45\n\nFirefox Mean Average Precision@3:   0.58\nVLC Mean Average Precision@3:       0.40\nSignal Mean Average Precision@3:    0.50\nNextcloud Mean Average Precision@3: 0.73\n\nFirefox Mean Average Precision@2:   0.54\nVLC Mean Average Precision@2:       0.38\nSignal Mean Average Precision@2:    0.47\nNextcloud Mean Average Precision@2: 0.73\n\nFirefox Mean Average Precision@1:   0.50\nVLC Mean Average Precision@1:       0.32\nSignal Mean Average Precision@1:    0.38\nNextcloud Mean Average Precision@1: 0.62\n"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def calculate_average_precision(issue_id, n=3):\n",
    "    scores = df[df[ISSUE_ID]==issue_id][[MATCHING, SIMILARITY]][:n]\n",
    "    ap = average_precision_score(scores[MATCHING], scores[SIMILARITY])\n",
    "    return ap if not np.isnan(ap) else 0\n",
    "\n",
    "def calculate_overall_at(n=3):\n",
    "    total = 0\n",
    "    issue_ids = df[ISSUE_ID].unique()\n",
    "    for issue_id in issue_ids:\n",
    "        ap = calculate_average_precision(issue_id, n)\n",
    "        total += ap\n",
    "\n",
    "    mean_average_precision = total/len(issue_ids)\n",
    "    print(f'{f\"Overall Mean Average Precision@{n}:\":<35} {mean_average_precision:.2f}')\n",
    "    print()\n",
    "\n",
    "calculate_overall_at(3)\n",
    "calculate_overall_at(2)\n",
    "calculate_overall_at(1)\n",
    "\n",
    "def calculate_map_at(n):\n",
    "    for app in Const.APPS:\n",
    "        app_matches = df[df['App']==app]\n",
    "        issue_ids = app_matches[ISSUE_ID].unique()\n",
    "        total = 0\n",
    "        for issue_id in issue_ids:\n",
    "            ap = calculate_average_precision(issue_id, n)\n",
    "            total += ap\n",
    "        app_mean_average_precision = total/len(issue_ids)\n",
    "        print(f'{app+f\" Mean Average Precision@{n}:\":<35} {app_mean_average_precision:>4.2f}')\n",
    "\n",
    "calculate_map_at(3)\n",
    "print()\n",
    "calculate_map_at(2)\n",
    "print()\n",
    "calculate_map_at(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Hit Ratio@3\nApp\nFirefox      0.74\nNextcloud    0.89\nSignal       0.68\nVLC          0.51\ndtype: float64\nHit Ratio@2\nApp\nFirefox      0.58\nNextcloud    0.84\nSignal       0.57\nVLC          0.44\ndtype: float64\nHit Ratio@1\nApp\nFirefox      0.50\nNextcloud    0.62\nSignal       0.38\nVLC          0.32\ndtype: float64\n"
    }
   ],
   "source": [
    "length=len(df)\n",
    "df['rank']=-1\n",
    "\n",
    "for i in range(length):\n",
    "    df.iat[i, list(df.columns).index('rank')]=int(i%3)+1\n",
    "\n",
    "def calculate_hit_ratio_at(df, n=3):\n",
    "    groups = df.groupby(['App', 'user_feedback_id']).agg({\n",
    "        MATCHING: np.count_nonzero\n",
    "    })\n",
    "    groups.reset_index(inplace=True)\n",
    "    values = pd.pivot_table(groups, index=['App'], columns=MATCHING, aggfunc='size', fill_value=0)\n",
    "\n",
    "    hits = values[values.columns[1:]].sum(axis=1) if len(values.columns)>2 else values[1]\n",
    "    total = values[0]+hits\n",
    "    hit_ratio = hits/total\n",
    "\n",
    "    print(f'Hit Ratio@{n}')\n",
    "    print(hit_ratio.round(2))\n",
    "\n",
    "rank3 = df\n",
    "rank2 = df[df['rank']<=2]\n",
    "rank1 = df[df['rank']<=1]\n",
    "calculate_hit_ratio_at(rank3, 3)\n",
    "calculate_hit_ratio_at(rank2, 2)\n",
    "calculate_hit_ratio_at(rank1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}